{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n"
      ],
      "metadata": {
        "id": "1jD01oOWG9Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-geometric\n"
      ],
      "metadata": {
        "id": "VTjhOcNeCXb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTds5Ny0FUdu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from torch_geometric.nn import GCNConv\n",
        "from scipy.sparse import identity\n",
        "from torch_geometric.utils import from_scipy_sparse_matrix\n",
        "\n",
        "from random import sample\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise Exception(\"You should enable GPU runtime\")\n",
        "device = torch.device(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing\n"
      ],
      "metadata": {
        "id": "sh8p7fW3G9AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "url = 'https://raw.githubusercontent.com/vfayosp/project_aidl2022/main/data/mat_drug_protein.txt'\n",
        "\n",
        "data = pd.read_csv(url, sep=' ',decimal = ',')"
      ],
      "metadata": {
        "id": "dvtlGKQOGab8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "data.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb1LeSUR5zCx",
        "outputId": "3d8da686-30b7-457e-841b-3ae3c25664ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "707"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdX2SLOb68SE",
        "outputId": "216bf579-56f7-41ac-8a35-e35513f51954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(707, 1512)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.utils.data\n",
        "from tqdm import tqdm\n",
        "import scipy.sparse as sp\n",
        "\n",
        "def build_adj_mx(dims, interactions):\n",
        "    train_mat = sp.dok_matrix((dims, dims), dtype=np.float32)\n",
        "    for x in tqdm(interactions, desc=\"BUILDING ADJACENCY MATRIX...\"):\n",
        "        train_mat[x[0], x[1]] = 1.0\n",
        "        train_mat[x[1], x[0]] = 1.0\n",
        "\n",
        "    return train_mat\n",
        "\n",
        "#Create the masks --> Train, Validation & Test\n",
        "class DiseaseDrugDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, full_dataset, n_train = 0.95 ,n_val = 0, num_negatives_train=4, num_negatives_test=100):\n",
        "    \"\"\"\n",
        "    data is the rows containing all the interactions of a drug with the diseases\n",
        "    n_train is the amount of training data that the dataset will compute\n",
        "    n_val is the amount of validation data that the dataset will compute\n",
        "\n",
        "    ITEMS\n",
        "    data = matrix with the disease drug interaction\n",
        "    num_drugs = number of drugs \n",
        "    num_diseases = number of diseases\n",
        "\n",
        "    train_mask = boolean vector with the training mask\n",
        "    train_drugs = number of the drugs in the training set\n",
        "    train_data = pandas dataframe with samples for the training set\n",
        "\n",
        "    val_mask = boolean vector with the validation mask\n",
        "    val_drugs = number of the drugs in the validation set\n",
        "    val_data = pandas dataframe with samples for the validation set\n",
        "\n",
        "    test_mask = boolean vector with the test mask\n",
        "    test_drugs = number of the drugs in the test set\n",
        "    test_data = pandas dataframe with samples for the test set\n",
        "    \"\"\"\n",
        "    #falta definir si aqui se le pone ya la matriz con las interacciones o solo los datos limpios\n",
        "    #y aqui ya se hace la matriz con las interacciones\n",
        "    \n",
        "    self.nitems = full_dataset.shape[0]\n",
        "\n",
        "    #self.full_dataset = [[i, j, full_dataset[i, j]] for i in range(full_dataset.shape[0]) for j in range(full_dataset.shape[1]) if full_dataset[i, j] == 1]\n",
        "    #self.data = sample(self.full_dataset, int(self.nitems * n_train))\n",
        "    #self.test_data = [i for i in self.full_dataset if i not in self.data]\n",
        "\n",
        "    self.data = pd.read_csv(\"https://raw.githubusercontent.com/luciapp97/upc/main/train2.csv\", sep=' ',decimal = ',')\n",
        "    self.test_data = pd.read_csv(\"https://raw.githubusercontent.com/luciapp97/upc/main/test2.csv\", sep=' ',decimal = ',')\n",
        "\n",
        "    self.data = pd.DataFrame(self.data).to_numpy()\n",
        "    self.test_data = pd.DataFrame(self.test_data).to_numpy()\n",
        "    self.items = self.preprocess_items(self.data)\n",
        "    self.targets = self.data[:, 2]\n",
        "\n",
        "    self.field_dims = np.max(self.items, axis = 0) + 1\n",
        "    print(len(self.items))\n",
        "    self.train_mat = build_adj_mx(self.field_dims[-1], self.items.copy())\n",
        "    self.negative_sampling(num_negatives = num_negatives_train)\n",
        "\n",
        "    self.test_set = self.build_test_set(self.preprocess_items(self.test_data),\n",
        "                                        num_neg_samples_test = num_negatives_test)\n",
        "  def __len__(self):\n",
        "      return self.targets.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      return self.interactions[index]\n",
        "\n",
        "  def negative_sampling(self, num_negatives = 4):\n",
        "        self.interactions = []\n",
        "        data = np.c_[(self.items, self.targets)].astype(int)\n",
        "        max_users, max_items = self.field_dims[:2] \n",
        "\n",
        "        for x in tqdm(data, desc=\"Performing negative sampling on test data...\"):  # x are triplets (u, i , 1) \n",
        "            # Append positive interaction\n",
        "            self.interactions.append(x)\n",
        "            # Copy user and maintain last position to 0. Now we will need to update neg_triplet[1] with j\n",
        "            neg_triplet = np.vstack([x, ] * (num_negatives))\n",
        "            neg_triplet[:, 2] = np.zeros(num_negatives)\n",
        "\n",
        "            # Generate num_negatives negative interactions\n",
        "            for idx in range(num_negatives):\n",
        "                j = np.random.randint(max_users, max_items)\n",
        "                # IDEA: Loop to exclude true interactions (set to 1 in adj_train) user - item\n",
        "                while (x[0], j) in self.train_mat:\n",
        "                    j = np.random.randint(max_users, max_items)\n",
        "                neg_triplet[:, 1][idx] = j\n",
        "            self.interactions.append(neg_triplet.copy())\n",
        "\n",
        "        self.interactions = np.vstack(self.interactions)\n",
        "\n",
        "  def preprocess_items(self, data):\n",
        "        \n",
        "        reindexed_items = data[:, :2].astype(np.int)  # -1 because ID begins from 1\n",
        "        #users, items = np.max(reindexed_items, axis=0)[:2] + 1 # [ 943, 1682])\n",
        "        reindexed_items[:, 1] = reindexed_items[:, 1] + self.nitems\n",
        "\n",
        "        return reindexed_items\n",
        "\n",
        "  def build_test_set(self, gt_test_interactions, num_neg_samples_test=99):\n",
        "        max_users, max_items = self.field_dims[:2] \n",
        "        test_set = []\n",
        "        for pair in tqdm(gt_test_interactions, desc=\"BUILDING TEST SET...\"):\n",
        "            negatives = []\n",
        "            for t in range(num_neg_samples_test):\n",
        "                j = np.random.randint(max_users, max_items)\n",
        "                while (pair[0], j) in self.train_mat or j == pair[1]:\n",
        "                    j = np.random.randint(max_users, max_items)\n",
        "                negatives.append(j)\n",
        "\n",
        "            single_user_test_set = np.vstack([pair, ] * (len(negatives)+1))\n",
        "            single_user_test_set[:, 1][1:] = negatives\n",
        "            test_set.append(single_user_test_set.copy())\n",
        "        return test_set"
      ],
      "metadata": {
        "id": "oeTnEqhagd6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DiseaseDrugDataset(data, num_negatives_test=709)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03e1gGm0m88G",
        "outputId": "2890e608-6258-43a7-fd45-e5c17c38d706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:95: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BUILDING ADJACENCY MATRIX...: 100%|██████████| 1742/1742 [00:00<00:00, 35559.31it/s]\n",
            "Performing negative sampling on test data...: 100%|██████████| 1742/1742 [00:00<00:00, 17885.90it/s]\n",
            "BUILDING TEST SET...: 100%|██████████| 368/368 [00:01<00:00, 226.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.data[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig9vNe2O5Qx3",
        "outputId": "a99efa11-fcf0-4fb6-e0ae-5872d7f74ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "623"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(dataset.data)):\n",
        "  #print(f'Iteration {i} : {dataset.data[i][0]}')\n",
        "  # assert dataset.test_set[i][0][0] == i\n",
        "    if dataset.data[i][0] == 8:\n",
        "      print ('hola')\n",
        "\n",
        "print(\"todo ok\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVCtMxdTx0fu",
        "outputId": "6d765060-2089-41f8-ca1c-576183e5f35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "todo ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)\n",
        "\n",
        "tb = True \n",
        "\n",
        "%load_ext tensorboard \n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "tb_fm = SummaryWriter(log_dir=f'{logs_base_dir}/{logs_base_dir}_FM/')\n",
        "tb_gcn = SummaryWriter(log_dir=f'{logs_base_dir}/{logs_base_dir}_GCN/')\n",
        "tb_gcn_attention = SummaryWriter(log_dir=f'{logs_base_dir}/{logs_base_dir}_GCN_att/')"
      ],
      "metadata": {
        "id": "61nP1bIseLzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FactorizationMachineModel"
      ],
      "metadata": {
        "id": "vRPmQuUyt9wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=0)\n",
        "\n",
        "\n",
        "def getHitRatio(recommend_list, gt_item):\n",
        "    if gt_item in recommend_list:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def getNDCG(recommend_list, gt_item):\n",
        "    idx = np.where(recommend_list == gt_item)[0]\n",
        "    if len(idx) > 0:\n",
        "        return math.log(2)/math.log(idx+2)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Linear part of the equation\n",
        "class FeaturesLinear(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, field_dims, output_dim=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = torch.nn.Embedding(field_dims, output_dim)\n",
        "        self.bias = torch.nn.Parameter(torch.zeros((output_dim,)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        # self.fc(x).shape --> [batch_size, num_fields, 1]\n",
        "        # torch.sum(self.fc(x), dim=1).shape --> ([batch_size, 1])\n",
        "        return torch.sum(self.fc(x), dim=1) + self.bias\n",
        "        #return self.fc(x).squeeze(1) + self.bias\n",
        "\n",
        "# FM part of the equation\n",
        "class FM_operation(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, reduce_sum=True):\n",
        "        super().__init__()\n",
        "        self.reduce_sum = reduce_sum\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Float tensor of size ``(batch_size, num_fields, embed_dim)``\n",
        "        \"\"\"\n",
        "        square_of_sum = torch.sum(x, dim=1) ** 2\n",
        "        sum_of_square = torch.sum(x ** 2, dim=1)\n",
        "        ix = square_of_sum - sum_of_square\n",
        "        if self.reduce_sum:\n",
        "            ix = torch.sum(ix, dim=1, keepdim=True)\n",
        "        return 0.5 * ix\n",
        "\n",
        "class FactorizationMachineModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A pytorch implementation of Factorization Machine.\n",
        "\n",
        "    Reference:\n",
        "        S Rendle, Factorization Machines, 2010.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, field_dims, embed_dim):\n",
        "        super().__init__()\n",
        "        # field_dims == total of nodes (sum users + context)\n",
        "        #self.linear = torch.nn.Linear(field_dims, 1, bias=True)\n",
        "        self.linear = FeaturesLinear(field_dims)\n",
        "        self.embedding = torch.nn.Embedding(field_dims, embed_dim, sparse=False)\n",
        "        self.fm = FM_operation(reduce_sum=True)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
        "\n",
        "    def forward(self, interaction_pairs):\n",
        "        \"\"\"\n",
        "        :param interaction_pairs: Long tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        out = self.linear(interaction_pairs) + self.fm(self.embedding(interaction_pairs))\n",
        "        \n",
        "        return out.squeeze(1)\n",
        "        \n",
        "    def predict(self, interactions, device):\n",
        "        # return the score, inputs are numpy arrays, outputs are tensors\n",
        " \n",
        "        test_interactions = torch.from_numpy(interactions).to(dtype=torch.long, device=device)\n",
        "        output_scores = self.forward(test_interactions)\n",
        "        return output_scores\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, criterion, device, log_interval=100):\n",
        "    model.train()\n",
        "    total_loss = []\n",
        "\n",
        "    for i, (interactions) in enumerate(data_loader):\n",
        "        interactions = interactions.to(device)\n",
        "        targets = interactions[:,2]\n",
        "        predictions = model(interactions[:,:2])\n",
        "        \n",
        "        loss = criterion(predictions, targets.float())\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss.append(loss.item())\n",
        "\n",
        "    return mean(total_loss)\n",
        "\n",
        "def test(model, full_dataset, device, topk=11):\n",
        "    # Test the HR and NDCG for the model @topK\n",
        "    model.eval()\n",
        "\n",
        "    HR, NDCG = [], []\n",
        "    i = 0\n",
        "    for user_test in full_dataset.test_set:\n",
        "        i+=1\n",
        "        gt_item = user_test[0][1]\n",
        "        predictions = model.predict(user_test, device)\n",
        "        _, indices = torch.topk(predictions, topk)\n",
        "        indices = indices.cpu().detach().numpy()\n",
        "        recommend_list = user_test[indices][:, 1]\n",
        "        HR.append(getHitRatio(recommend_list, gt_item))\n",
        "        NDCG.append(getNDCG(recommend_list, gt_item))\n",
        "    return mean(HR), mean(NDCG)\n",
        "\n",
        "model = FactorizationMachineModel(dataset.field_dims[-1], 32).to(device)\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "# DO EPOCHS NOW\n",
        "tb = True\n",
        "topk = 10\n",
        "for epoch_i in range(150):\n",
        "    #data_loader.dataset.negative_sampling()\n",
        "    train_loss = train_one_epoch(model, optimizer, data_loader, criterion, device)\n",
        "    hr, ndcg = test(model, dataset, device, topk=topk)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(f'epoch {epoch_i}:')\n",
        "    print(f'training loss = {train_loss:.4f} | Eval: HR@{topk} = {hr:.4f}, NDCG@{topk} = {ndcg:.4f} ')\n",
        "    print('\\n')\n",
        "\n",
        "    if tb:\n",
        "        tb_fm.add_scalar('train/loss', train_loss, epoch_i)\n",
        "        tb_fm.add_scalar('eval/HR@{topk}', hr, epoch_i)\n",
        "        tb_fm.add_scalar('eval/NDCG@{topk}', ndcg, epoch_i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKU8-6fowoFS",
        "outputId": "fa8d4293-0537-4273-9378-d27b2694b76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "epoch 0:\n",
            "training loss = 0.9399 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0051 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 1:\n",
            "training loss = 0.9320 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0052 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 2:\n",
            "training loss = 0.9273 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0052 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 3:\n",
            "training loss = 0.9200 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0052 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 4:\n",
            "training loss = 0.9138 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0052 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 5:\n",
            "training loss = 0.9076 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0052 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 6:\n",
            "training loss = 0.8996 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0052 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 7:\n",
            "training loss = 0.8920 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0052 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 8:\n",
            "training loss = 0.8834 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0051 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 9:\n",
            "training loss = 0.8738 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0051 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 10:\n",
            "training loss = 0.8670 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0051 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 11:\n",
            "training loss = 0.8584 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 12:\n",
            "training loss = 0.8493 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 13:\n",
            "training loss = 0.8395 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 14:\n",
            "training loss = 0.8310 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 15:\n",
            "training loss = 0.8202 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 16:\n",
            "training loss = 0.8082 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 17:\n",
            "training loss = 0.7942 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0048 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 18:\n",
            "training loss = 0.7844 | Eval: HR@10 = 0.0109, NDCG@10 = 0.0040 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 19:\n",
            "training loss = 0.7710 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0049 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 20:\n",
            "training loss = 0.7569 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0049 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 21:\n",
            "training loss = 0.7449 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 22:\n",
            "training loss = 0.7288 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 23:\n",
            "training loss = 0.7161 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 24:\n",
            "training loss = 0.6994 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 25:\n",
            "training loss = 0.6847 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0051 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 26:\n",
            "training loss = 0.6697 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0051 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 27:\n",
            "training loss = 0.6511 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0051 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 28:\n",
            "training loss = 0.6356 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0051 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 29:\n",
            "training loss = 0.6200 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 30:\n",
            "training loss = 0.6026 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0050 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 31:\n",
            "training loss = 0.5864 | Eval: HR@10 = 0.0163, NDCG@10 = 0.0058 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 32:\n",
            "training loss = 0.5696 | Eval: HR@10 = 0.0190, NDCG@10 = 0.0068 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 33:\n",
            "training loss = 0.5525 | Eval: HR@10 = 0.0190, NDCG@10 = 0.0069 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 34:\n",
            "training loss = 0.5349 | Eval: HR@10 = 0.0217, NDCG@10 = 0.0077 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 35:\n",
            "training loss = 0.5199 | Eval: HR@10 = 0.0217, NDCG@10 = 0.0080 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 36:\n",
            "training loss = 0.5032 | Eval: HR@10 = 0.0217, NDCG@10 = 0.0081 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 37:\n",
            "training loss = 0.4862 | Eval: HR@10 = 0.0245, NDCG@10 = 0.0087 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 38:\n",
            "training loss = 0.4691 | Eval: HR@10 = 0.0272, NDCG@10 = 0.0098 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 39:\n",
            "training loss = 0.4516 | Eval: HR@10 = 0.0272, NDCG@10 = 0.0104 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 40:\n",
            "training loss = 0.4360 | Eval: HR@10 = 0.0272, NDCG@10 = 0.0106 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 41:\n",
            "training loss = 0.4210 | Eval: HR@10 = 0.0299, NDCG@10 = 0.0113 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 42:\n",
            "training loss = 0.4047 | Eval: HR@10 = 0.0299, NDCG@10 = 0.0114 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 43:\n",
            "training loss = 0.3910 | Eval: HR@10 = 0.0299, NDCG@10 = 0.0116 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 44:\n",
            "training loss = 0.3760 | Eval: HR@10 = 0.0353, NDCG@10 = 0.0134 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 45:\n",
            "training loss = 0.3617 | Eval: HR@10 = 0.0353, NDCG@10 = 0.0139 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 46:\n",
            "training loss = 0.3481 | Eval: HR@10 = 0.0353, NDCG@10 = 0.0146 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 47:\n",
            "training loss = 0.3346 | Eval: HR@10 = 0.0353, NDCG@10 = 0.0151 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 48:\n",
            "training loss = 0.3219 | Eval: HR@10 = 0.0408, NDCG@10 = 0.0170 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 49:\n",
            "training loss = 0.3095 | Eval: HR@10 = 0.0435, NDCG@10 = 0.0182 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 50:\n",
            "training loss = 0.2980 | Eval: HR@10 = 0.0435, NDCG@10 = 0.0187 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 51:\n",
            "training loss = 0.2853 | Eval: HR@10 = 0.0489, NDCG@10 = 0.0214 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 52:\n",
            "training loss = 0.2742 | Eval: HR@10 = 0.0516, NDCG@10 = 0.0241 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 53:\n",
            "training loss = 0.2624 | Eval: HR@10 = 0.0516, NDCG@10 = 0.0241 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 54:\n",
            "training loss = 0.2523 | Eval: HR@10 = 0.0571, NDCG@10 = 0.0263 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 55:\n",
            "training loss = 0.2423 | Eval: HR@10 = 0.0571, NDCG@10 = 0.0270 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 56:\n",
            "training loss = 0.2325 | Eval: HR@10 = 0.0625, NDCG@10 = 0.0298 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 57:\n",
            "training loss = 0.2232 | Eval: HR@10 = 0.0652, NDCG@10 = 0.0319 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 58:\n",
            "training loss = 0.2146 | Eval: HR@10 = 0.0679, NDCG@10 = 0.0342 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 59:\n",
            "training loss = 0.2056 | Eval: HR@10 = 0.0734, NDCG@10 = 0.0361 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 60:\n",
            "training loss = 0.1973 | Eval: HR@10 = 0.0842, NDCG@10 = 0.0402 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 61:\n",
            "training loss = 0.1897 | Eval: HR@10 = 0.0870, NDCG@10 = 0.0437 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 62:\n",
            "training loss = 0.1821 | Eval: HR@10 = 0.0951, NDCG@10 = 0.0468 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 63:\n",
            "training loss = 0.1755 | Eval: HR@10 = 0.0978, NDCG@10 = 0.0497 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 64:\n",
            "training loss = 0.1680 | Eval: HR@10 = 0.1005, NDCG@10 = 0.0509 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 65:\n",
            "training loss = 0.1618 | Eval: HR@10 = 0.1033, NDCG@10 = 0.0541 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 66:\n",
            "training loss = 0.1560 | Eval: HR@10 = 0.1087, NDCG@10 = 0.0561 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 67:\n",
            "training loss = 0.1500 | Eval: HR@10 = 0.1114, NDCG@10 = 0.0577 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 68:\n",
            "training loss = 0.1436 | Eval: HR@10 = 0.1168, NDCG@10 = 0.0609 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 69:\n",
            "training loss = 0.1390 | Eval: HR@10 = 0.1196, NDCG@10 = 0.0632 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 70:\n",
            "training loss = 0.1332 | Eval: HR@10 = 0.1223, NDCG@10 = 0.0657 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 71:\n",
            "training loss = 0.1288 | Eval: HR@10 = 0.1277, NDCG@10 = 0.0676 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 72:\n",
            "training loss = 0.1239 | Eval: HR@10 = 0.1332, NDCG@10 = 0.0721 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 73:\n",
            "training loss = 0.1196 | Eval: HR@10 = 0.1359, NDCG@10 = 0.0763 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 74:\n",
            "training loss = 0.1152 | Eval: HR@10 = 0.1413, NDCG@10 = 0.0788 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 75:\n",
            "training loss = 0.1111 | Eval: HR@10 = 0.1440, NDCG@10 = 0.0813 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 76:\n",
            "training loss = 0.1074 | Eval: HR@10 = 0.1440, NDCG@10 = 0.0821 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 77:\n",
            "training loss = 0.1034 | Eval: HR@10 = 0.1495, NDCG@10 = 0.0867 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 78:\n",
            "training loss = 0.0998 | Eval: HR@10 = 0.1522, NDCG@10 = 0.0905 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 79:\n",
            "training loss = 0.0964 | Eval: HR@10 = 0.1603, NDCG@10 = 0.0931 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 80:\n",
            "training loss = 0.0931 | Eval: HR@10 = 0.1630, NDCG@10 = 0.0958 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 81:\n",
            "training loss = 0.0902 | Eval: HR@10 = 0.1658, NDCG@10 = 0.0990 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 82:\n",
            "training loss = 0.0869 | Eval: HR@10 = 0.1658, NDCG@10 = 0.1016 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 83:\n",
            "training loss = 0.0842 | Eval: HR@10 = 0.1685, NDCG@10 = 0.1028 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 84:\n",
            "training loss = 0.0817 | Eval: HR@10 = 0.1712, NDCG@10 = 0.1040 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 85:\n",
            "training loss = 0.0791 | Eval: HR@10 = 0.1739, NDCG@10 = 0.1068 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 86:\n",
            "training loss = 0.0767 | Eval: HR@10 = 0.1739, NDCG@10 = 0.1094 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 87:\n",
            "training loss = 0.0740 | Eval: HR@10 = 0.1766, NDCG@10 = 0.1116 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 88:\n",
            "training loss = 0.0721 | Eval: HR@10 = 0.1793, NDCG@10 = 0.1127 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 89:\n",
            "training loss = 0.0697 | Eval: HR@10 = 0.1793, NDCG@10 = 0.1138 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 90:\n",
            "training loss = 0.0677 | Eval: HR@10 = 0.1793, NDCG@10 = 0.1147 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 91:\n",
            "training loss = 0.0657 | Eval: HR@10 = 0.1793, NDCG@10 = 0.1166 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 92:\n",
            "training loss = 0.0639 | Eval: HR@10 = 0.1821, NDCG@10 = 0.1189 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 93:\n",
            "training loss = 0.0618 | Eval: HR@10 = 0.1848, NDCG@10 = 0.1203 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 94:\n",
            "training loss = 0.0602 | Eval: HR@10 = 0.1848, NDCG@10 = 0.1195 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 95:\n",
            "training loss = 0.0584 | Eval: HR@10 = 0.1875, NDCG@10 = 0.1211 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 96:\n",
            "training loss = 0.0569 | Eval: HR@10 = 0.1875, NDCG@10 = 0.1214 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 97:\n",
            "training loss = 0.0554 | Eval: HR@10 = 0.1875, NDCG@10 = 0.1217 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 98:\n",
            "training loss = 0.0538 | Eval: HR@10 = 0.1902, NDCG@10 = 0.1239 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 99:\n",
            "training loss = 0.0525 | Eval: HR@10 = 0.1902, NDCG@10 = 0.1251 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 100:\n",
            "training loss = 0.0510 | Eval: HR@10 = 0.1929, NDCG@10 = 0.1273 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 101:\n",
            "training loss = 0.0497 | Eval: HR@10 = 0.1957, NDCG@10 = 0.1302 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 102:\n",
            "training loss = 0.0484 | Eval: HR@10 = 0.1957, NDCG@10 = 0.1304 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 103:\n",
            "training loss = 0.0472 | Eval: HR@10 = 0.1957, NDCG@10 = 0.1308 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 104:\n",
            "training loss = 0.0460 | Eval: HR@10 = 0.1957, NDCG@10 = 0.1311 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 105:\n",
            "training loss = 0.0449 | Eval: HR@10 = 0.1957, NDCG@10 = 0.1326 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 106:\n",
            "training loss = 0.0438 | Eval: HR@10 = 0.1957, NDCG@10 = 0.1327 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 107:\n",
            "training loss = 0.0427 | Eval: HR@10 = 0.1984, NDCG@10 = 0.1365 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 108:\n",
            "training loss = 0.0417 | Eval: HR@10 = 0.1984, NDCG@10 = 0.1380 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 109:\n",
            "training loss = 0.0406 | Eval: HR@10 = 0.1984, NDCG@10 = 0.1392 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 110:\n",
            "training loss = 0.0396 | Eval: HR@10 = 0.2011, NDCG@10 = 0.1404 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 111:\n",
            "training loss = 0.0387 | Eval: HR@10 = 0.2011, NDCG@10 = 0.1408 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 112:\n",
            "training loss = 0.0379 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1436 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 113:\n",
            "training loss = 0.0370 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1443 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 114:\n",
            "training loss = 0.0361 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1454 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 115:\n",
            "training loss = 0.0354 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1482 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 116:\n",
            "training loss = 0.0346 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1488 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 117:\n",
            "training loss = 0.0338 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1489 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 118:\n",
            "training loss = 0.0330 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1497 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 119:\n",
            "training loss = 0.0325 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1499 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 120:\n",
            "training loss = 0.0317 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1514 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 121:\n",
            "training loss = 0.0310 | Eval: HR@10 = 0.2038, NDCG@10 = 0.1555 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 122:\n",
            "training loss = 0.0303 | Eval: HR@10 = 0.2092, NDCG@10 = 0.1589 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 123:\n",
            "training loss = 0.0297 | Eval: HR@10 = 0.2092, NDCG@10 = 0.1592 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 124:\n",
            "training loss = 0.0291 | Eval: HR@10 = 0.2120, NDCG@10 = 0.1613 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 125:\n",
            "training loss = 0.0285 | Eval: HR@10 = 0.2120, NDCG@10 = 0.1613 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 126:\n",
            "training loss = 0.0279 | Eval: HR@10 = 0.2120, NDCG@10 = 0.1617 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 127:\n",
            "training loss = 0.0274 | Eval: HR@10 = 0.2120, NDCG@10 = 0.1631 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 128:\n",
            "training loss = 0.0268 | Eval: HR@10 = 0.2120, NDCG@10 = 0.1632 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 129:\n",
            "training loss = 0.0263 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1661 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 130:\n",
            "training loss = 0.0258 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1663 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 131:\n",
            "training loss = 0.0253 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1663 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 132:\n",
            "training loss = 0.0248 | Eval: HR@10 = 0.2174, NDCG@10 = 0.1676 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 133:\n",
            "training loss = 0.0243 | Eval: HR@10 = 0.2174, NDCG@10 = 0.1678 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 134:\n",
            "training loss = 0.0239 | Eval: HR@10 = 0.2174, NDCG@10 = 0.1678 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 135:\n",
            "training loss = 0.0234 | Eval: HR@10 = 0.2174, NDCG@10 = 0.1682 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 136:\n",
            "training loss = 0.0230 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1684 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 137:\n",
            "training loss = 0.0226 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1694 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 138:\n",
            "training loss = 0.0221 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1694 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 139:\n",
            "training loss = 0.0218 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1697 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 140:\n",
            "training loss = 0.0214 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1703 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 141:\n",
            "training loss = 0.0210 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1706 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 142:\n",
            "training loss = 0.0207 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1711 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 143:\n",
            "training loss = 0.0203 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1716 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 144:\n",
            "training loss = 0.0200 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1726 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 145:\n",
            "training loss = 0.0196 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1727 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 146:\n",
            "training loss = 0.0193 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1732 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 147:\n",
            "training loss = 0.0189 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1742 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 148:\n",
            "training loss = 0.0186 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1742 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 149:\n",
            "training loss = 0.0183 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1743 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "uVJDx1uceepH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "872e808e-041a-4a2b-ca94-c55df4fb15b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FM with GCN"
      ],
      "metadata": {
        "id": "dNa-t5QZuADS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import identity\n",
        "from torch_geometric.utils import from_scipy_sparse_matrix\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\" Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "from torch_geometric.nn import GCNConv, GATConv # https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html?highlight=GCNConv#torch_geometric.nn.conv.GCNConv\n",
        "from torch_geometric.utils import from_scipy_sparse_matrix\n",
        "\n",
        "class GraphModel(torch.nn.Module):\n",
        "    def __init__(self, field_dims, embed_dim, features, train_mat, attention=False):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.A = train_mat\n",
        "        self.features = features\n",
        "        if attention:\n",
        "            self.GCN_module = GATConv(int(field_dims), embed_dim, heads=8, dropout=0.6)\n",
        "        else:  \n",
        "            self.GCN_module = GCNConv(field_dims, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: Long tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        return self.GCN_module(self.features, self.A)[x]\n",
        "\n",
        "class FactorizationMachineModel_withGCN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A pytorch implementation of Factorization Machine.\n",
        "\n",
        "    Reference:\n",
        "        S Rendle, Factorization Machines, 2010.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, field_dims, embed_dim, X, A, attention=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear = FeaturesLinear(field_dims)\n",
        "        #self.embedding = torch.nn.Embedding(field_dims, embed_dim, sparse=False)\n",
        "        self.embedding = GraphModel(field_dims, embed_dim, X, A, attention=attention)\n",
        "        self.fm = FM_operation(reduce_sum=True)\n",
        "\n",
        "        #torch.nn.init.xavier_uniform_(self.embedding.weight.data)\n",
        "\n",
        "    def forward(self, interaction_pairs):\n",
        "        \"\"\"\n",
        "        :param interaction_pairs: Long tensor of size ``(batch_size, num_fields)``\n",
        "        \"\"\"\n",
        "        out = self.linear(interaction_pairs) + self.fm(self.embedding(interaction_pairs))\n",
        "        return out.squeeze(1)\n",
        "        \n",
        "    def predict(self, interactions, device):\n",
        "        # return the score, inputs are numpy arrays, outputs are tensors\n",
        " \n",
        "        test_interactions = torch.from_numpy(interactions).to(dtype=torch.long, device=device)\n",
        "        output_scores = self.forward(test_interactions)\n",
        "        return output_scores"
      ],
      "metadata": {
        "id": "VvhC49o6uYO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = sparse_mx_to_torch_sparse_tensor(identity(dataset.train_mat.shape[0]))\n",
        "edge_idx, edge_attr = from_scipy_sparse_matrix(dataset.train_mat)\n",
        "model_gcn = FactorizationMachineModel_withGCN(dataset.field_dims[-1],\n",
        "                                              64,\n",
        "                                              X.to(device),\n",
        "                                              edge_idx.to(device),\n",
        "                                              ).to(device)\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(params=model_gcn.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "7GiTbcHKuxVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topk = 10\n",
        "for epoch_i in range(150):\n",
        "    #data_loader.dataset.negative_sampling()\n",
        "    train_loss = train_one_epoch(model_gcn, optimizer, data_loader, criterion, device)\n",
        "    hr, ndcg = test(model_gcn, dataset, device, topk=topk)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(f'epoch {epoch_i}:')\n",
        "    print(f'training loss = {train_loss:.4f} | Eval: HR@{topk} = {hr:.4f}, NDCG@{topk} = {ndcg:.4f} ')\n",
        "    print('\\n')\n",
        "    if tb:\n",
        "        tb_gcn.add_scalar('train/loss', train_loss, epoch_i)\n",
        "        tb_gcn.add_scalar('eval/HR@{topk}', hr, epoch_i)\n",
        "        tb_gcn.add_scalar('eval/NDCG@{topk}', ndcg, epoch_i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzfzuh4-v7We",
        "outputId": "41b8c311-56df-4441-ab1e-b642d51a6093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "epoch 0:\n",
            "training loss = 0.8761 | Eval: HR@10 = 0.0027, NDCG@10 = 0.0027 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 1:\n",
            "training loss = 0.8722 | Eval: HR@10 = 0.0027, NDCG@10 = 0.0027 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 2:\n",
            "training loss = 0.8643 | Eval: HR@10 = 0.0027, NDCG@10 = 0.0027 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 3:\n",
            "training loss = 0.8560 | Eval: HR@10 = 0.0027, NDCG@10 = 0.0027 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 4:\n",
            "training loss = 0.8507 | Eval: HR@10 = 0.0027, NDCG@10 = 0.0027 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 5:\n",
            "training loss = 0.8400 | Eval: HR@10 = 0.0027, NDCG@10 = 0.0027 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 6:\n",
            "training loss = 0.8315 | Eval: HR@10 = 0.0027, NDCG@10 = 0.0027 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 7:\n",
            "training loss = 0.8203 | Eval: HR@10 = 0.0054, NDCG@10 = 0.0035 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 8:\n",
            "training loss = 0.8084 | Eval: HR@10 = 0.0082, NDCG@10 = 0.0043 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 9:\n",
            "training loss = 0.7970 | Eval: HR@10 = 0.0136, NDCG@10 = 0.0061 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 10:\n",
            "training loss = 0.7797 | Eval: HR@10 = 0.0190, NDCG@10 = 0.0079 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 11:\n",
            "training loss = 0.7647 | Eval: HR@10 = 0.0299, NDCG@10 = 0.0124 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 12:\n",
            "training loss = 0.7468 | Eval: HR@10 = 0.0353, NDCG@10 = 0.0157 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 13:\n",
            "training loss = 0.7267 | Eval: HR@10 = 0.0408, NDCG@10 = 0.0179 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 14:\n",
            "training loss = 0.7090 | Eval: HR@10 = 0.0571, NDCG@10 = 0.0247 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 15:\n",
            "training loss = 0.6850 | Eval: HR@10 = 0.0598, NDCG@10 = 0.0303 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 16:\n",
            "training loss = 0.6647 | Eval: HR@10 = 0.0652, NDCG@10 = 0.0396 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 17:\n",
            "training loss = 0.6430 | Eval: HR@10 = 0.0870, NDCG@10 = 0.0482 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 18:\n",
            "training loss = 0.6196 | Eval: HR@10 = 0.1141, NDCG@10 = 0.0615 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 19:\n",
            "training loss = 0.5975 | Eval: HR@10 = 0.1332, NDCG@10 = 0.0752 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 20:\n",
            "training loss = 0.5724 | Eval: HR@10 = 0.1495, NDCG@10 = 0.0901 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 21:\n",
            "training loss = 0.5506 | Eval: HR@10 = 0.1603, NDCG@10 = 0.0998 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 22:\n",
            "training loss = 0.5283 | Eval: HR@10 = 0.1821, NDCG@10 = 0.1147 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 23:\n",
            "training loss = 0.5056 | Eval: HR@10 = 0.2011, NDCG@10 = 0.1308 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 24:\n",
            "training loss = 0.4825 | Eval: HR@10 = 0.2147, NDCG@10 = 0.1429 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 25:\n",
            "training loss = 0.4621 | Eval: HR@10 = 0.2418, NDCG@10 = 0.1575 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 26:\n",
            "training loss = 0.4433 | Eval: HR@10 = 0.2609, NDCG@10 = 0.1695 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 27:\n",
            "training loss = 0.4220 | Eval: HR@10 = 0.2826, NDCG@10 = 0.1849 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 28:\n",
            "training loss = 0.4036 | Eval: HR@10 = 0.3016, NDCG@10 = 0.1949 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 29:\n",
            "training loss = 0.3836 | Eval: HR@10 = 0.3179, NDCG@10 = 0.2124 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 30:\n",
            "training loss = 0.3654 | Eval: HR@10 = 0.3315, NDCG@10 = 0.2286 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 31:\n",
            "training loss = 0.3491 | Eval: HR@10 = 0.3424, NDCG@10 = 0.2352 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 32:\n",
            "training loss = 0.3338 | Eval: HR@10 = 0.3560, NDCG@10 = 0.2485 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 33:\n",
            "training loss = 0.3181 | Eval: HR@10 = 0.3587, NDCG@10 = 0.2623 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 34:\n",
            "training loss = 0.3036 | Eval: HR@10 = 0.3696, NDCG@10 = 0.2769 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 35:\n",
            "training loss = 0.2890 | Eval: HR@10 = 0.3777, NDCG@10 = 0.2827 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 36:\n",
            "training loss = 0.2762 | Eval: HR@10 = 0.3940, NDCG@10 = 0.2943 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 37:\n",
            "training loss = 0.2634 | Eval: HR@10 = 0.3967, NDCG@10 = 0.2996 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 38:\n",
            "training loss = 0.2507 | Eval: HR@10 = 0.4049, NDCG@10 = 0.3094 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 39:\n",
            "training loss = 0.2397 | Eval: HR@10 = 0.4185, NDCG@10 = 0.3187 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 40:\n",
            "training loss = 0.2283 | Eval: HR@10 = 0.4266, NDCG@10 = 0.3252 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 41:\n",
            "training loss = 0.2183 | Eval: HR@10 = 0.4321, NDCG@10 = 0.3344 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 42:\n",
            "training loss = 0.2088 | Eval: HR@10 = 0.4402, NDCG@10 = 0.3426 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 43:\n",
            "training loss = 0.1994 | Eval: HR@10 = 0.4402, NDCG@10 = 0.3499 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 44:\n",
            "training loss = 0.1922 | Eval: HR@10 = 0.4484, NDCG@10 = 0.3542 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 45:\n",
            "training loss = 0.1830 | Eval: HR@10 = 0.4538, NDCG@10 = 0.3585 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 46:\n",
            "training loss = 0.1759 | Eval: HR@10 = 0.4592, NDCG@10 = 0.3646 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 47:\n",
            "training loss = 0.1668 | Eval: HR@10 = 0.4592, NDCG@10 = 0.3708 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 48:\n",
            "training loss = 0.1605 | Eval: HR@10 = 0.4674, NDCG@10 = 0.3764 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 49:\n",
            "training loss = 0.1545 | Eval: HR@10 = 0.4701, NDCG@10 = 0.3820 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 50:\n",
            "training loss = 0.1472 | Eval: HR@10 = 0.4701, NDCG@10 = 0.3851 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 51:\n",
            "training loss = 0.1424 | Eval: HR@10 = 0.4728, NDCG@10 = 0.3878 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 52:\n",
            "training loss = 0.1359 | Eval: HR@10 = 0.4810, NDCG@10 = 0.3923 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 53:\n",
            "training loss = 0.1303 | Eval: HR@10 = 0.4946, NDCG@10 = 0.3992 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 54:\n",
            "training loss = 0.1259 | Eval: HR@10 = 0.4946, NDCG@10 = 0.4005 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 55:\n",
            "training loss = 0.1201 | Eval: HR@10 = 0.4973, NDCG@10 = 0.4029 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 56:\n",
            "training loss = 0.1157 | Eval: HR@10 = 0.5054, NDCG@10 = 0.4089 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 57:\n",
            "training loss = 0.1113 | Eval: HR@10 = 0.5136, NDCG@10 = 0.4132 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 58:\n",
            "training loss = 0.1073 | Eval: HR@10 = 0.5217, NDCG@10 = 0.4175 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 59:\n",
            "training loss = 0.1029 | Eval: HR@10 = 0.5217, NDCG@10 = 0.4181 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 60:\n",
            "training loss = 0.0997 | Eval: HR@10 = 0.5245, NDCG@10 = 0.4194 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 61:\n",
            "training loss = 0.0957 | Eval: HR@10 = 0.5245, NDCG@10 = 0.4223 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 62:\n",
            "training loss = 0.0925 | Eval: HR@10 = 0.5299, NDCG@10 = 0.4258 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 63:\n",
            "training loss = 0.0891 | Eval: HR@10 = 0.5380, NDCG@10 = 0.4294 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 64:\n",
            "training loss = 0.0858 | Eval: HR@10 = 0.5380, NDCG@10 = 0.4303 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 65:\n",
            "training loss = 0.0831 | Eval: HR@10 = 0.5380, NDCG@10 = 0.4313 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 66:\n",
            "training loss = 0.0805 | Eval: HR@10 = 0.5408, NDCG@10 = 0.4318 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 67:\n",
            "training loss = 0.0775 | Eval: HR@10 = 0.5435, NDCG@10 = 0.4333 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 68:\n",
            "training loss = 0.0752 | Eval: HR@10 = 0.5435, NDCG@10 = 0.4334 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 69:\n",
            "training loss = 0.0725 | Eval: HR@10 = 0.5408, NDCG@10 = 0.4351 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 70:\n",
            "training loss = 0.0704 | Eval: HR@10 = 0.5408, NDCG@10 = 0.4353 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 71:\n",
            "training loss = 0.0678 | Eval: HR@10 = 0.5408, NDCG@10 = 0.4358 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 72:\n",
            "training loss = 0.0662 | Eval: HR@10 = 0.5408, NDCG@10 = 0.4372 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 73:\n",
            "training loss = 0.0640 | Eval: HR@10 = 0.5408, NDCG@10 = 0.4381 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 74:\n",
            "training loss = 0.0618 | Eval: HR@10 = 0.5408, NDCG@10 = 0.4384 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 75:\n",
            "training loss = 0.0603 | Eval: HR@10 = 0.5408, NDCG@10 = 0.4395 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 76:\n",
            "training loss = 0.0588 | Eval: HR@10 = 0.5489, NDCG@10 = 0.4423 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 77:\n",
            "training loss = 0.0566 | Eval: HR@10 = 0.5489, NDCG@10 = 0.4450 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 78:\n",
            "training loss = 0.0547 | Eval: HR@10 = 0.5516, NDCG@10 = 0.4457 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 79:\n",
            "training loss = 0.0531 | Eval: HR@10 = 0.5543, NDCG@10 = 0.4464 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 80:\n",
            "training loss = 0.0517 | Eval: HR@10 = 0.5571, NDCG@10 = 0.4476 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 81:\n",
            "training loss = 0.0505 | Eval: HR@10 = 0.5571, NDCG@10 = 0.4485 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 82:\n",
            "training loss = 0.0491 | Eval: HR@10 = 0.5598, NDCG@10 = 0.4504 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 83:\n",
            "training loss = 0.0479 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4524 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 84:\n",
            "training loss = 0.0465 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4529 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 85:\n",
            "training loss = 0.0455 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4554 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 86:\n",
            "training loss = 0.0441 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4566 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 87:\n",
            "training loss = 0.0429 | Eval: HR@10 = 0.5598, NDCG@10 = 0.4560 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 88:\n",
            "training loss = 0.0418 | Eval: HR@10 = 0.5598, NDCG@10 = 0.4573 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 89:\n",
            "training loss = 0.0406 | Eval: HR@10 = 0.5598, NDCG@10 = 0.4575 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 90:\n",
            "training loss = 0.0396 | Eval: HR@10 = 0.5571, NDCG@10 = 0.4572 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 91:\n",
            "training loss = 0.0387 | Eval: HR@10 = 0.5543, NDCG@10 = 0.4574 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 92:\n",
            "training loss = 0.0377 | Eval: HR@10 = 0.5571, NDCG@10 = 0.4589 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 93:\n",
            "training loss = 0.0368 | Eval: HR@10 = 0.5571, NDCG@10 = 0.4590 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 94:\n",
            "training loss = 0.0359 | Eval: HR@10 = 0.5598, NDCG@10 = 0.4604 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 95:\n",
            "training loss = 0.0351 | Eval: HR@10 = 0.5598, NDCG@10 = 0.4606 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 96:\n",
            "training loss = 0.0340 | Eval: HR@10 = 0.5598, NDCG@10 = 0.4608 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 97:\n",
            "training loss = 0.0334 | Eval: HR@10 = 0.5598, NDCG@10 = 0.4612 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 98:\n",
            "training loss = 0.0326 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4629 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 99:\n",
            "training loss = 0.0319 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4648 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 100:\n",
            "training loss = 0.0310 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4651 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 101:\n",
            "training loss = 0.0305 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4673 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 102:\n",
            "training loss = 0.0298 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4673 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 103:\n",
            "training loss = 0.0291 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4670 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 104:\n",
            "training loss = 0.0285 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4671 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 105:\n",
            "training loss = 0.0279 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4682 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 106:\n",
            "training loss = 0.0274 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4694 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 107:\n",
            "training loss = 0.0267 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4695 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 108:\n",
            "training loss = 0.0262 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4699 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 109:\n",
            "training loss = 0.0258 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4699 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 110:\n",
            "training loss = 0.0253 | Eval: HR@10 = 0.5625, NDCG@10 = 0.4719 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 111:\n",
            "training loss = 0.0246 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4729 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 112:\n",
            "training loss = 0.0241 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4739 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 113:\n",
            "training loss = 0.0236 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4745 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 114:\n",
            "training loss = 0.0232 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4742 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 115:\n",
            "training loss = 0.0227 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4742 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 116:\n",
            "training loss = 0.0224 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4742 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 117:\n",
            "training loss = 0.0219 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4744 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 118:\n",
            "training loss = 0.0213 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4743 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 119:\n",
            "training loss = 0.0210 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4744 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 120:\n",
            "training loss = 0.0206 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4762 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 121:\n",
            "training loss = 0.0202 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4758 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 122:\n",
            "training loss = 0.0198 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4773 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 123:\n",
            "training loss = 0.0195 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4783 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 124:\n",
            "training loss = 0.0191 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4793 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 125:\n",
            "training loss = 0.0188 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4798 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 126:\n",
            "training loss = 0.0185 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4799 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 127:\n",
            "training loss = 0.0182 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4800 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 128:\n",
            "training loss = 0.0178 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4800 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 129:\n",
            "training loss = 0.0175 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4800 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 130:\n",
            "training loss = 0.0173 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4802 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 131:\n",
            "training loss = 0.0170 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4802 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 132:\n",
            "training loss = 0.0166 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4803 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 133:\n",
            "training loss = 0.0163 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4818 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 134:\n",
            "training loss = 0.0161 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4818 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 135:\n",
            "training loss = 0.0159 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4816 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 136:\n",
            "training loss = 0.0155 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4817 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 137:\n",
            "training loss = 0.0154 | Eval: HR@10 = 0.5707, NDCG@10 = 0.4832 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 138:\n",
            "training loss = 0.0151 | Eval: HR@10 = 0.5707, NDCG@10 = 0.4832 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 139:\n",
            "training loss = 0.0147 | Eval: HR@10 = 0.5707, NDCG@10 = 0.4845 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 140:\n",
            "training loss = 0.0146 | Eval: HR@10 = 0.5707, NDCG@10 = 0.4845 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 141:\n",
            "training loss = 0.0143 | Eval: HR@10 = 0.5707, NDCG@10 = 0.4845 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 142:\n",
            "training loss = 0.0144 | Eval: HR@10 = 0.5707, NDCG@10 = 0.4846 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 143:\n",
            "training loss = 0.0139 | Eval: HR@10 = 0.5707, NDCG@10 = 0.4847 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 144:\n",
            "training loss = 0.0136 | Eval: HR@10 = 0.5734, NDCG@10 = 0.4855 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 145:\n",
            "training loss = 0.0136 | Eval: HR@10 = 0.5734, NDCG@10 = 0.4856 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 146:\n",
            "training loss = 0.0133 | Eval: HR@10 = 0.5734, NDCG@10 = 0.4856 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 147:\n",
            "training loss = 0.0131 | Eval: HR@10 = 0.5734, NDCG@10 = 0.4856 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 148:\n",
            "training loss = 0.0128 | Eval: HR@10 = 0.5734, NDCG@10 = 0.4857 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 149:\n",
            "training loss = 0.0126 | Eval: HR@10 = 0.5734, NDCG@10 = 0.4856 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN ATT"
      ],
      "metadata": {
        "id": "vDXm1PPtwUCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_gcn_att = FactorizationMachineModel_withGCN(dataset.field_dims[-1],\n",
        "                                                  64,\n",
        "                                                  X.to(device),\n",
        "                                                  edge_idx.to(device),\n",
        "                                                  attention=True\n",
        "                                                  ).to(device)\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(params=model_gcn_att.parameters(), lr=0.001)\n",
        "for epoch_i in range(150):\n",
        "    #data_loader.dataset.negative_sampling()\n",
        "    train_loss = train_one_epoch(model_gcn_att, optimizer, data_loader, criterion, device)\n",
        "    hr, ndcg = test(model_gcn_att, dataset, device, topk=topk)\n",
        "\n",
        "    print('\\n')\n",
        "\n",
        "    print(f'epoch {epoch_i}:')\n",
        "    print(f'training loss = {train_loss:.4f} | Eval: HR@{topk} = {hr:.4f}, NDCG@{topk} = {ndcg:.4f} ')\n",
        "    print('\\n')\n",
        "    if tb:\n",
        "        tb_gcn_attention.add_scalar('train/loss', train_loss, epoch_i)\n",
        "        tb_gcn_attention.add_scalar('eval/HR@{topk}', hr, epoch_i)\n",
        "        tb_gcn_attention.add_scalar('eval/NDCG@{topk}', ndcg, epoch_i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoYFqTwywaD2",
        "outputId": "8d93701d-0349-482a-d893-2d5317aa6ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "epoch 0:\n",
            "training loss = 0.7947 | Eval: HR@10 = 0.0245, NDCG@10 = 0.0083 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 1:\n",
            "training loss = 0.7884 | Eval: HR@10 = 0.0245, NDCG@10 = 0.0084 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 2:\n",
            "training loss = 0.7793 | Eval: HR@10 = 0.0272, NDCG@10 = 0.0092 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 3:\n",
            "training loss = 0.7711 | Eval: HR@10 = 0.0272, NDCG@10 = 0.0093 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 4:\n",
            "training loss = 0.7606 | Eval: HR@10 = 0.0272, NDCG@10 = 0.0094 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 5:\n",
            "training loss = 0.7515 | Eval: HR@10 = 0.0272, NDCG@10 = 0.0096 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 6:\n",
            "training loss = 0.7378 | Eval: HR@10 = 0.0272, NDCG@10 = 0.0096 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 7:\n",
            "training loss = 0.7276 | Eval: HR@10 = 0.0299, NDCG@10 = 0.0106 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 8:\n",
            "training loss = 0.7127 | Eval: HR@10 = 0.0326, NDCG@10 = 0.0118 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 9:\n",
            "training loss = 0.6987 | Eval: HR@10 = 0.0353, NDCG@10 = 0.0129 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 10:\n",
            "training loss = 0.6764 | Eval: HR@10 = 0.0462, NDCG@10 = 0.0174 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 11:\n",
            "training loss = 0.6562 | Eval: HR@10 = 0.0679, NDCG@10 = 0.0299 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 12:\n",
            "training loss = 0.6315 | Eval: HR@10 = 0.0707, NDCG@10 = 0.0388 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 13:\n",
            "training loss = 0.6070 | Eval: HR@10 = 0.0734, NDCG@10 = 0.0451 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 14:\n",
            "training loss = 0.5824 | Eval: HR@10 = 0.0788, NDCG@10 = 0.0509 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 15:\n",
            "training loss = 0.5517 | Eval: HR@10 = 0.0842, NDCG@10 = 0.0558 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 16:\n",
            "training loss = 0.5277 | Eval: HR@10 = 0.0951, NDCG@10 = 0.0617 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 17:\n",
            "training loss = 0.4907 | Eval: HR@10 = 0.1114, NDCG@10 = 0.0715 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 18:\n",
            "training loss = 0.4655 | Eval: HR@10 = 0.1223, NDCG@10 = 0.0779 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 19:\n",
            "training loss = 0.4386 | Eval: HR@10 = 0.1359, NDCG@10 = 0.0845 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 20:\n",
            "training loss = 0.4143 | Eval: HR@10 = 0.1793, NDCG@10 = 0.1023 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 21:\n",
            "training loss = 0.3856 | Eval: HR@10 = 0.2092, NDCG@10 = 0.1166 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 22:\n",
            "training loss = 0.3638 | Eval: HR@10 = 0.2337, NDCG@10 = 0.1308 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 23:\n",
            "training loss = 0.3461 | Eval: HR@10 = 0.2473, NDCG@10 = 0.1455 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 24:\n",
            "training loss = 0.3303 | Eval: HR@10 = 0.2636, NDCG@10 = 0.1601 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 25:\n",
            "training loss = 0.3060 | Eval: HR@10 = 0.2935, NDCG@10 = 0.1772 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 26:\n",
            "training loss = 0.2855 | Eval: HR@10 = 0.3043, NDCG@10 = 0.1921 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 27:\n",
            "training loss = 0.2690 | Eval: HR@10 = 0.3207, NDCG@10 = 0.2040 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 28:\n",
            "training loss = 0.2495 | Eval: HR@10 = 0.3478, NDCG@10 = 0.2222 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 29:\n",
            "training loss = 0.2357 | Eval: HR@10 = 0.3696, NDCG@10 = 0.2341 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 30:\n",
            "training loss = 0.2229 | Eval: HR@10 = 0.3859, NDCG@10 = 0.2441 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 31:\n",
            "training loss = 0.2106 | Eval: HR@10 = 0.4130, NDCG@10 = 0.2579 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 32:\n",
            "training loss = 0.1979 | Eval: HR@10 = 0.4266, NDCG@10 = 0.2700 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 33:\n",
            "training loss = 0.1879 | Eval: HR@10 = 0.4321, NDCG@10 = 0.2801 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 34:\n",
            "training loss = 0.1829 | Eval: HR@10 = 0.4429, NDCG@10 = 0.2902 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 35:\n",
            "training loss = 0.1665 | Eval: HR@10 = 0.4592, NDCG@10 = 0.3063 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 36:\n",
            "training loss = 0.1633 | Eval: HR@10 = 0.4674, NDCG@10 = 0.3159 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 37:\n",
            "training loss = 0.1536 | Eval: HR@10 = 0.4701, NDCG@10 = 0.3239 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 38:\n",
            "training loss = 0.1541 | Eval: HR@10 = 0.4783, NDCG@10 = 0.3274 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 39:\n",
            "training loss = 0.1433 | Eval: HR@10 = 0.4891, NDCG@10 = 0.3331 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 40:\n",
            "training loss = 0.1341 | Eval: HR@10 = 0.4918, NDCG@10 = 0.3387 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 41:\n",
            "training loss = 0.1350 | Eval: HR@10 = 0.5027, NDCG@10 = 0.3469 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 42:\n",
            "training loss = 0.1220 | Eval: HR@10 = 0.5109, NDCG@10 = 0.3520 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 43:\n",
            "training loss = 0.1125 | Eval: HR@10 = 0.5136, NDCG@10 = 0.3560 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 44:\n",
            "training loss = 0.1132 | Eval: HR@10 = 0.5245, NDCG@10 = 0.3625 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 45:\n",
            "training loss = 0.1098 | Eval: HR@10 = 0.5245, NDCG@10 = 0.3646 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 46:\n",
            "training loss = 0.1098 | Eval: HR@10 = 0.5245, NDCG@10 = 0.3650 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 47:\n",
            "training loss = 0.1165 | Eval: HR@10 = 0.5190, NDCG@10 = 0.3660 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 48:\n",
            "training loss = 0.0969 | Eval: HR@10 = 0.5272, NDCG@10 = 0.3710 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 49:\n",
            "training loss = 0.0956 | Eval: HR@10 = 0.5380, NDCG@10 = 0.3742 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 50:\n",
            "training loss = 0.0934 | Eval: HR@10 = 0.5380, NDCG@10 = 0.3782 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 51:\n",
            "training loss = 0.0934 | Eval: HR@10 = 0.5353, NDCG@10 = 0.3793 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 52:\n",
            "training loss = 0.0835 | Eval: HR@10 = 0.5408, NDCG@10 = 0.3841 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 53:\n",
            "training loss = 0.0811 | Eval: HR@10 = 0.5462, NDCG@10 = 0.3864 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 54:\n",
            "training loss = 0.0806 | Eval: HR@10 = 0.5462, NDCG@10 = 0.3874 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 55:\n",
            "training loss = 0.0767 | Eval: HR@10 = 0.5462, NDCG@10 = 0.3885 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 56:\n",
            "training loss = 0.0774 | Eval: HR@10 = 0.5516, NDCG@10 = 0.3918 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 57:\n",
            "training loss = 0.0730 | Eval: HR@10 = 0.5543, NDCG@10 = 0.3920 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 58:\n",
            "training loss = 0.0756 | Eval: HR@10 = 0.5625, NDCG@10 = 0.3959 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 59:\n",
            "training loss = 0.0715 | Eval: HR@10 = 0.5625, NDCG@10 = 0.3961 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 60:\n",
            "training loss = 0.0686 | Eval: HR@10 = 0.5571, NDCG@10 = 0.3973 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 61:\n",
            "training loss = 0.0688 | Eval: HR@10 = 0.5571, NDCG@10 = 0.3995 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 62:\n",
            "training loss = 0.0652 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4038 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 63:\n",
            "training loss = 0.0654 | Eval: HR@10 = 0.5652, NDCG@10 = 0.4066 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 64:\n",
            "training loss = 0.0609 | Eval: HR@10 = 0.5679, NDCG@10 = 0.4076 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 65:\n",
            "training loss = 0.0635 | Eval: HR@10 = 0.5707, NDCG@10 = 0.4074 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 66:\n",
            "training loss = 0.0528 | Eval: HR@10 = 0.5761, NDCG@10 = 0.4103 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 67:\n",
            "training loss = 0.0672 | Eval: HR@10 = 0.5788, NDCG@10 = 0.4139 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 68:\n",
            "training loss = 0.0608 | Eval: HR@10 = 0.5815, NDCG@10 = 0.4151 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 69:\n",
            "training loss = 0.0549 | Eval: HR@10 = 0.5761, NDCG@10 = 0.4139 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 70:\n",
            "training loss = 0.0508 | Eval: HR@10 = 0.5761, NDCG@10 = 0.4154 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 71:\n",
            "training loss = 0.0543 | Eval: HR@10 = 0.5815, NDCG@10 = 0.4128 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 72:\n",
            "training loss = 0.0516 | Eval: HR@10 = 0.5815, NDCG@10 = 0.4129 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 73:\n",
            "training loss = 0.0524 | Eval: HR@10 = 0.5842, NDCG@10 = 0.4192 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 74:\n",
            "training loss = 0.0523 | Eval: HR@10 = 0.5842, NDCG@10 = 0.4190 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 75:\n",
            "training loss = 0.0503 | Eval: HR@10 = 0.5842, NDCG@10 = 0.4200 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 76:\n",
            "training loss = 0.0489 | Eval: HR@10 = 0.5870, NDCG@10 = 0.4208 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 77:\n",
            "training loss = 0.0512 | Eval: HR@10 = 0.5870, NDCG@10 = 0.4213 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 78:\n",
            "training loss = 0.0487 | Eval: HR@10 = 0.5870, NDCG@10 = 0.4187 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 79:\n",
            "training loss = 0.0424 | Eval: HR@10 = 0.5870, NDCG@10 = 0.4175 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 80:\n",
            "training loss = 0.0456 | Eval: HR@10 = 0.5897, NDCG@10 = 0.4156 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 81:\n",
            "training loss = 0.0451 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4167 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 82:\n",
            "training loss = 0.0435 | Eval: HR@10 = 0.5897, NDCG@10 = 0.4176 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 83:\n",
            "training loss = 0.0444 | Eval: HR@10 = 0.5897, NDCG@10 = 0.4193 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 84:\n",
            "training loss = 0.0400 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4201 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 85:\n",
            "training loss = 0.0410 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4211 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 86:\n",
            "training loss = 0.0359 | Eval: HR@10 = 0.5951, NDCG@10 = 0.4240 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 87:\n",
            "training loss = 0.0394 | Eval: HR@10 = 0.5951, NDCG@10 = 0.4236 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 88:\n",
            "training loss = 0.0394 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4243 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 89:\n",
            "training loss = 0.0349 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4248 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 90:\n",
            "training loss = 0.0378 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4247 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 91:\n",
            "training loss = 0.0337 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4245 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 92:\n",
            "training loss = 0.0389 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4246 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 93:\n",
            "training loss = 0.0372 | Eval: HR@10 = 0.5951, NDCG@10 = 0.4258 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 94:\n",
            "training loss = 0.0334 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4254 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 95:\n",
            "training loss = 0.0299 | Eval: HR@10 = 0.5924, NDCG@10 = 0.4241 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 96:\n",
            "training loss = 0.0349 | Eval: HR@10 = 0.6033, NDCG@10 = 0.4269 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 97:\n",
            "training loss = 0.0301 | Eval: HR@10 = 0.6033, NDCG@10 = 0.4281 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 98:\n",
            "training loss = 0.0365 | Eval: HR@10 = 0.6005, NDCG@10 = 0.4270 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 99:\n",
            "training loss = 0.0305 | Eval: HR@10 = 0.6005, NDCG@10 = 0.4284 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 100:\n",
            "training loss = 0.0312 | Eval: HR@10 = 0.6033, NDCG@10 = 0.4289 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 101:\n",
            "training loss = 0.0326 | Eval: HR@10 = 0.6060, NDCG@10 = 0.4310 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 102:\n",
            "training loss = 0.0340 | Eval: HR@10 = 0.6087, NDCG@10 = 0.4310 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 103:\n",
            "training loss = 0.0294 | Eval: HR@10 = 0.6087, NDCG@10 = 0.4319 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 104:\n",
            "training loss = 0.0337 | Eval: HR@10 = 0.6114, NDCG@10 = 0.4317 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 105:\n",
            "training loss = 0.0270 | Eval: HR@10 = 0.6087, NDCG@10 = 0.4298 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 106:\n",
            "training loss = 0.0310 | Eval: HR@10 = 0.6087, NDCG@10 = 0.4306 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 107:\n",
            "training loss = 0.0268 | Eval: HR@10 = 0.6087, NDCG@10 = 0.4306 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 108:\n",
            "training loss = 0.0292 | Eval: HR@10 = 0.6114, NDCG@10 = 0.4315 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 109:\n",
            "training loss = 0.0301 | Eval: HR@10 = 0.6141, NDCG@10 = 0.4325 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 110:\n",
            "training loss = 0.0285 | Eval: HR@10 = 0.6168, NDCG@10 = 0.4334 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 111:\n",
            "training loss = 0.0292 | Eval: HR@10 = 0.6168, NDCG@10 = 0.4337 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 112:\n",
            "training loss = 0.0289 | Eval: HR@10 = 0.6196, NDCG@10 = 0.4349 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 113:\n",
            "training loss = 0.0304 | Eval: HR@10 = 0.6196, NDCG@10 = 0.4344 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 114:\n",
            "training loss = 0.0235 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4365 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 115:\n",
            "training loss = 0.0196 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4348 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 116:\n",
            "training loss = 0.0253 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4348 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 117:\n",
            "training loss = 0.0272 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4346 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 118:\n",
            "training loss = 0.0257 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4352 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 119:\n",
            "training loss = 0.0234 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4345 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 120:\n",
            "training loss = 0.0229 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4350 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 121:\n",
            "training loss = 0.0210 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4350 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 122:\n",
            "training loss = 0.0252 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4358 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 123:\n",
            "training loss = 0.0225 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4349 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 124:\n",
            "training loss = 0.0224 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4349 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 125:\n",
            "training loss = 0.0257 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4358 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 126:\n",
            "training loss = 0.0203 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4362 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 127:\n",
            "training loss = 0.0235 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4361 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 128:\n",
            "training loss = 0.0230 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4348 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 129:\n",
            "training loss = 0.0211 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4349 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 130:\n",
            "training loss = 0.0186 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4343 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 131:\n",
            "training loss = 0.0212 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4352 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 132:\n",
            "training loss = 0.0250 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4357 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 133:\n",
            "training loss = 0.0208 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4362 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 134:\n",
            "training loss = 0.0223 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4355 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 135:\n",
            "training loss = 0.0247 | Eval: HR@10 = 0.6196, NDCG@10 = 0.4346 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 136:\n",
            "training loss = 0.0205 | Eval: HR@10 = 0.6196, NDCG@10 = 0.4343 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 137:\n",
            "training loss = 0.0189 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4348 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 138:\n",
            "training loss = 0.0201 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4361 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 139:\n",
            "training loss = 0.0206 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4351 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 140:\n",
            "training loss = 0.0207 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4338 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 141:\n",
            "training loss = 0.0177 | Eval: HR@10 = 0.6277, NDCG@10 = 0.4369 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 142:\n",
            "training loss = 0.0193 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4361 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 143:\n",
            "training loss = 0.0217 | Eval: HR@10 = 0.6277, NDCG@10 = 0.4353 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 144:\n",
            "training loss = 0.0198 | Eval: HR@10 = 0.6277, NDCG@10 = 0.4355 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 145:\n",
            "training loss = 0.0193 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4351 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 146:\n",
            "training loss = 0.0247 | Eval: HR@10 = 0.6223, NDCG@10 = 0.4360 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 147:\n",
            "training loss = 0.0199 | Eval: HR@10 = 0.6250, NDCG@10 = 0.4364 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 148:\n",
            "training loss = 0.0256 | Eval: HR@10 = 0.6277, NDCG@10 = 0.4375 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "epoch 149:\n",
            "training loss = 0.0208 | Eval: HR@10 = 0.6277, NDCG@10 = 0.4374 \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}